{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "81abe8f0-da4b-4b33-9194-ffa639f33dde",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "from pyspark.sql.functions import expr,to_date,col\n",
    "\n",
    "\n",
    "\n",
    "df_src1_raw = spark.read.options(header=True,inferSchema=True).format(\"csv\").load(\"/Volumes/workspace/logistics_data/logistics_volume/logistics_source1\")\n",
    "\n",
    "df_src2_raw = spark.read.options(header=True,inferSchema=True).format(\"csv\").load(\"/Volumes/workspace/logistics_data/logistics_volume/logistics_source2\")\n",
    "\n",
    "df_logistics_ship_raw = spark.read.options(header=True,inferSchema=True,multiline=True).format(\"json\").load(\"/Volumes/workspace/logistics_data/logistics_volume/logistics_shipment_detail_3000.json\")\n",
    "\n",
    "\n",
    "print('count of df_src1_raw:-',df_src1_raw.count())\n",
    "print('count of df_src2_raw:-',df_src2_raw.count())\n",
    "print('count of df_json_raw:-',df_logistics_ship_raw.count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5ff32b8e-aedc-40f9-a362-6cc52a40df9d",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Cell 2"
    }
   },
   "outputs": [],
   "source": [
    "# Task 1 and 2\n",
    "\n",
    "from pyspark.sql.functions import lit,to_date,col,expr,when,lower,upper,cast,current_timestamp, initcap,count\n",
    "from pyspark.sql.types import DecimalType\n",
    "\n",
    "df_src1_clned = df_src1_raw.withColumn(\"source\",lit(\"source1\"))\n",
    "df_src2_clned = df_src2_raw.withColumn(\"source\",lit(\"source2\"))\n",
    "# df_json_clned = df_json_raw.withColumn(\"source\",lit(\"source3\"))\n",
    "\n",
    "df_src_combined = df_src1_clned.unionByName(df_src2_clned,allowMissingColumns = True).select(\"shipment_id\",\"first_name\",\"last_name\",\"age\",\"role\",\"hub_location\",\"vehicle_type\",\"source\")\n",
    "\n",
    "df_user = df_src_combined.dropna(subset=[\"shipment_id\",\"role\"]) \\\n",
    "    .filter(col(\"first_name\").isNotNull() | col(\"last_name\").isNotNull()) \\\n",
    "    .filter(col(\"shipment_id\").rlike(\"^[0-9]+$\")) \\\n",
    "    .dropDuplicates([\"shipment_id\"]) \\\n",
    "    .withColumn(\"age\",when(col(\"age\").rlike(\"^[0-9]+$\"), col(\"age\").cast(\"int\")).otherwise(-1)) \\\n",
    "    .withColumn(\"vehicle_type\",when (col(\"vehicle_type\").isNull(),\"UNKNOWN\")\n",
    "    .when (lower(col(\"vehicle_type\")) == \"truck\", \"LMV\")\n",
    "    .when (lower(col(\"vehicle_type\")) == \"bike\", \"TwoWheeler\") \\\n",
    "    .otherwise(col(\"vehicle_type\"))) \\\n",
    "    .withColumn(\"role\",lower(col(\"role\"))) \\\n",
    "    .withColumn(\"vehicle_type\",upper(col(\"role\"))) \\\n",
    "    .withColumn(\"hub_location\",initcap(col(\"hub_location\"))) \\\n",
    "    .withColumnsRenamed({\"hub_location\":\"origin_hub_city\",\"first_name\":\"staff_first_name\",\"last_name\":\"staff_last_name\"})\n",
    "\n",
    "\n",
    "\n",
    "df_user=df_user.dropDuplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6f5cdd3f-189d-4cd1-9584-166a4b4c7f6e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    " \n",
    "df_log_data_stand =df_logistics_ship_raw.withColumn(\"domain\", lit(\"logistics\")) \\\n",
    "    .withColumn(\"ingestion_timestamp\", current_timestamp()) \\\n",
    "    .withColumn(\"is_expedited\", lit(\"False\")) \\\n",
    "    .withColumn(\"shipment_date\", to_date(col(\"shipment_date\"), 'yyyy-MM-dd')) \\\n",
    "    .withColumn(\"shipment_cost\", col(\"shipment_cost\").cast(DecimalType(15, 2))) \\\n",
    "    .withColumn(\"shipment_weight_kg\", col(\"shipment_weight_kg\").cast(\"double\"))\n",
    "\n",
    "\n",
    "df_log_standard=df_log_data_stand.withColumn(\"is_expedited\",col(\"is_expedited\") \\\n",
    "    .cast(\"boolean\"))\n",
    "# de duplication\n",
    "df_log_standard=df_log_standard.dropDuplicates()\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "86d6bced-4a99-4ddf-a76f-9473fc47b78b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "logistics_notebook",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
